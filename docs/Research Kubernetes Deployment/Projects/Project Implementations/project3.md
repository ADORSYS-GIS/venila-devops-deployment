# Project 3: Advanced Cluster Management and Monitoring

### Objective

Implement advanced features such as Horizontal Pod Autoscaling, Persistent Storage, and integrate monitoring tools.

## Steps
1. Set Up Persistent Storage

### Create PersistentVolume (PV) and PersistentVolumeClaim (PVC)

Create a YAML file for the PersistentVolume named `persistent-volume.yaml`:
```shell
apiVersion: v1
kind: PersistentVolume
metadata:
  name: my-pv
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /mnt/data  # Change this path as needed

```

Then, create a YAML file for the PersistentVolumeClaim named `persistent-volume-claim.yaml`:
```shell
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi

```
### Apply the PV and PVC

Run the following commands to create the PersistentVolume and PersistentVolumeClaim:
```shell
kubectl apply -f persistent-volume.yaml
kubectl apply -f persistent-volume-claim.yaml

```

### 2. Deploy an Application with Persistent Storage

### Modify the Deployment YAML

Now, modify the existing Nginx deployment to use the PVC for persistent storage. Create a new YAML file named `nginx-deployment-pvc.yaml`:

```shell
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: nginx-storage
          mountPath: /usr/share/nginx/html  # Path inside the container
      volumes:
      - name: nginx-storage
        persistentVolumeClaim:
          claimName: my-pvc  # Reference to the PVC

```

### Apply the Modified Deployment

Run the following command to apply the modified deployment:
```shell
kubectl apply -f nginx-deployment-pvc.yaml

```

### 3. Implement Horizontal Pod Autoscaling (HPA)

### Create HPA YAML

Create a YAML file named `hpa.yaml` to define the Horizontal Pod Autoscaler:

```shell
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 50

```

### Apply the HPA Configuration

Run the following command to create the HPA:
```shell
kubectl apply -f hpa.yaml

```

### 4. Set Up Monitoring and Logging

### Install Prometheus and Grafana

You can use Helm to install Prometheus and Grafana. If you donâ€™t have Helm installed, follow the [Helm installation guide](https://helm.sh/docs/intro/install/).

```shell
# Add the Prometheus community chart repository
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

# Update the Helm repos
helm repo update

# Install Prometheus
helm install prometheus prometheus-community/prometheus

# Install Grafana
helm install grafana grafana/grafana

```

### Access Grafana

Get the Grafana admin password:
```shell
kubectl get secret --namespace default grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo

```

Forward the Grafana port to access it locally:
```shell
kubectl port-forward service/grafana 3000:80

```

Access Grafana at `http://localhost:3000` using the username `admin` and the password you retrieved.

### Install ELK Stack (Elasticsearch, Logstash, Kibana)

You can install the ELK stack using Helm as well:

```shell
# Add the Elastic Helm repo
helm repo add elastic https://helm.elastic.co

# Update the Helm repos
helm repo update

# Install Elasticsearch
helm install elasticsearch elastic/elasticsearch

# Install Kibana
helm install kibana elastic/kibana

```

### Access Kibana

Forward the Kibana port to access it locally:
```shell
kubectl port-forward service/kibana-kibana 5601:5601

```

Access Kibana at http://localhost:5601.

### 5. Verify Autoscaling and Monitoring

### Test Autoscaling

To test autoscaling, you can generate load on the Nginx deployment. You can use a tool like kubectl run to create a load generator:
```shell
kubectl run -i --tty load-generator --image=busybox /bin/sh

```

Inside the pod, run:

```shell
while true; do wget -q -O- http://nginx-service; done

```

Monitor the HPA status:

```shell
kubectl get hpa

```

### Monitor with Grafana

Use Grafana to visualize metrics. You can create dashboards to monitor CPU usage, memory usage, and other metrics.

### 6. Analyze Logs with Kibana

In Kibana, you can set up an index pattern to view logs. This will help you analyze logs generated by your application.

### Troubleshooting and Optimization

- Review Metrics: Use Grafana to view CPU and memory metrics.
- Review Logs: Use Kibana to analyze logs for errors or issues.
- Optimize Resources: Adjust resource requests and limits in your deployment based on the observed metrics.

### Outcome

By completing these steps, you will have implemented advanced Kubernetes features such as:

- Persistent Storage using PV and PVC.
- Horizontal Pod Autoscaling based on CPU utilization.
- Monitoring with Prometheus and Grafana.
- Logging with the ELK stack.

This project will provide you with a deep understanding of managing and monitoring Kubernetes clusters. If you have any questions or need further assistance with any part of the implementation, feel free to ask!